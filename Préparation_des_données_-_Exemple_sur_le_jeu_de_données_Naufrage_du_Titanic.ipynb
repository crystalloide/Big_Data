{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crystalloide/Big_Data/blob/master/Pr%C3%A9paration_des_donn%C3%A9es_-_Exemple_sur_le_jeu_de_donn%C3%A9es_Naufrage_du_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade kagglehub"
      ],
      "metadata": {
        "id": "ExFT8AtGYGLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# IMPORTANT : CERTAINES SOURCES DE DONNÉES KAGGLE SONT PRIVÉES\n",
        "# EXÉCUTEZ CETTE CELLULE POUR IMPORTER VOS SOURCES DE DONNÉES KAGGLE.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "6UkNvlzy8muH"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT : EXÉCUTEZ CETTE CELLULE POUR IMPORTER VOS SOURCES DE DONNÉES KAGGLE,\n",
        "# PUIS, N'HÉSITEZ PAS À SUPPRIMER CETTE CELLULE.\n",
        "# REMARQUE : CET ENVIRONNEMENT PORTABLE DIFFÈRE DE L'ENVIRONNEMENT PYTHON DE KAGGLE.\n",
        "# IL PEUT DONC MANQUER DES BIBLIOTHÈQUES UTILISÉES PAR VOTRE PORTABLE.\n",
        "\n",
        "titanic_path = kagglehub.competition_download('titanic')\n",
        "\n",
        "print('Data source import complete.')\n",
        "\n",
        "!ls\n",
        "!pwd\n",
        "!rm gender_submission.csv\n",
        "!rm test.csv\n",
        "!rm train.csv\n",
        "!unzip /titanic.zip\n",
        "\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "fzH-yyjN8muI"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "_uuid": "fa1c06c3245237b07d584ac9984675953f90bcc2",
        "id": "fhurNBsc8muI"
      },
      "cell_type": "markdown",
      "source": [
        "# **Tutoriel général de préparation des données**\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "4bbfe635e70581311314c3d6111742a953d20e3d",
        "id": "mZOayC6m8muJ"
      },
      "cell_type": "markdown",
      "source": [
        "### Bienvenue dans ce tutoriel de préparation de données. Ce notebook est destiné aux débutants qui souhaitent apprendre à préparer correctement un jeu de données afin de le transmettre à un algorithme de machine learning. Je vous encourage à créer un fork de ce notebook, à tester le code et à l'améliorer !"
      ]
    },
    {
      "metadata": {
        "_uuid": "ab319b6d81ba9248843b1ad2758d3878a384c466",
        "id": "-TAyCIyJ8muJ"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://2s7gjr373w3x22jf92z99mgm5w-wpengine.netdna-ssl.com/wp-content/uploads/2016/07/shutterstock_data_prep_-faithie.jpg)"
      ]
    },
    {
      "metadata": {
        "_uuid": "b578e8fc813355bbcf0e887c0120c4ddb5b14ab6",
        "id": "AYWWwBrb8muJ"
      },
      "cell_type": "markdown",
      "source": [
        "### Voici quelques ressources supplémentaires que vous pouvez consulter pour approfondir la compréhension des différentes techniques que nous allons voir dans ce cahier :"
      ]
    },
    {
      "metadata": {
        "_uuid": "50283e1cb80921d96364b582dafad1723512d221",
        "id": "B0fQB43m8muK"
      },
      "cell_type": "markdown",
      "source": [
        "[*Gérer les valeurs manquantes*](https://towardsdatascience.com/tag/handling-missing-values/)\n",
        "\n",
        "[*Ingénierie des fonctionnalités*](https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/)\n",
        "\n",
        "[*Pourquoi l'encodage à chaud en apprentissage automatique ?*](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/)\n",
        "\n",
        "[*Piège à variables fictives*](https://www.algosome.com/articles/dummy-variable-trap-regression.html)\n",
        "\n",
        "[*Encodage à chaud*](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding)\n",
        "\n",
        "[*Mise à l'échelle et Normalisation*](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CnKnCHkvRMhU"
      }
    },
    {
      "metadata": {
        "_uuid": "685dee8f16e05ef7eb8b90078aba46e802ecd61a",
        "id": "9av9L91-8muK"
      },
      "cell_type": "markdown",
      "source": [
        "## **Table des matières**"
      ]
    },
    {
      "metadata": {
        "_uuid": "386676783fb199ab10ceac466ed8ffd4aa206b86",
        "id": "4D2WZSz08muK"
      },
      "cell_type": "markdown",
      "source": [
        "[**1. Traitement des valeurs manquantes et des valeurs aberrantes**](#1)\n",
        "\n",
        "[**2. Ingénierie des caractéristiques**](#2)\n",
        "\n",
        "[**3. Gestion des fonctionnalités catégorielles**](#3)\n",
        "\n",
        "[**4. Mise à l'échelle des caractéristiques**](#4)"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "ZXIfpn4r8muK"
      },
      "cell_type": "code",
      "source": [
        "!pip install chart-studio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import missingno as mn\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Remplacement des imports obsolètes de Plotly\n",
        "import chart_studio.plotly as py\n",
        "import plotly.graph_objects as go\n",
        "from plotly.offline import iplot, init_notebook_mode\n",
        "import cufflinks\n",
        "cufflinks.go_offline(connected=True)\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def draw_missing_data_table(df):\n",
        "    total = df.isnull().sum().sort_values(ascending=False)\n",
        "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
        "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "    return missing_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "FrD_aPy98muL"
      },
      "cell_type": "code",
      "source": [
        "# Path of datasets\n",
        "titanic_df = pd.read_csv('train.csv')\n",
        "titanic_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ddd3eba2b4f6366ab0d98f469a15cc0450a85941",
        "id": "EDK0oT2c8muL"
      },
      "cell_type": "markdown",
      "source": [
        "## **1. Traitement des valeurs manquantes et des valeurs aberrantes** <a id=\"1\"></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "a831e5f105f5ac9cf9cab593833b0602991cbe5c",
        "id": "yKd5w2698muL"
      },
      "cell_type": "markdown",
      "source": [
        "#### Le premier problème rencontré lors de la préparation des données pour leur transmission à un algorithme d'apprentissage automatique est celui des données manquantes. En effet, la plupart des jeux de données, notamment ceux issus de données réelles, présentent des valeurs manquantes. Par exemple, notre jeu de données titanesque présente des valeurs manquantes :"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8253704df6dc5b0f0d74e35b661b8ec428bd8195",
        "id": "XQsYBDEG8muL"
      },
      "cell_type": "code",
      "source": [
        "missing_values = titanic_df\n",
        "sns.heatmap(missing_values.isnull(), cbar=False)\n",
        "# Option 1 :\n",
        "plt.show()\n",
        "# Option 2 :\n",
        "mn.matrix(missing_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5392a9719179a729cf1ef15b50c59c3a438fb1b8",
        "id": "6LJoGCUV8muL"
      },
      "cell_type": "markdown",
      "source": [
        "### Si une caractéristique (une colonne de notre jeu de données) ne présente pas trop de valeurs manquantes, nous pouvons essayer de les compléter. Il existe plusieurs méthodes pour ce faire :\n",
        "\n",
        "- S'il y a trop de données manquantes (> 60 %), vous pouvez supprimer la colonne :\n",
        "\n",
        "titanic_df.drop('Cabin', axis=1, inplace=True)\n",
        "\n",
        "- S'il y a peu de données manquantes (1 à 2 %), vous pouvez supprimer les lignes contenant NAN :\n",
        "\n",
        "titanic_df['Age'].dropna(inplace=True)\n",
        "\n",
        "### Une meilleure solution pour un petit nombre de données manquantes consiste à étudier chaque observation au cas par cas et à remplacer les valeurs manquantes en examinant d'autres caractéristiques de cette observation, puis en essayant de trouver une tendance entre elles afin de déterminer la valeur manquante.\n",
        "\n",
        "- En général, nous ne souhaitons pas perdre de données. Une solution consiste à remplacer les valeurs manquantes par la moyenne ou la médiane de la colonne. Privilégiez la médiane pour les colonnes contenant des valeurs aberrantes susceptibles de fausser la moyenne.\n",
        "\n",
        "titanic_df['Age'].fillna(titanic_df['Age'].mean(), 1, inplace=True)\n",
        "titanic_df['Age'].fillna(titanic_df['Age'].median(), 1, inplace=True)\n",
        "\n",
        "### La stratégie de remplissage des valeurs manquantes dépend fortement du jeu de données et de votre imagination ! Soyez donc créatifs, demandez-vous pourquoi ces données sont manquantes et comment les remplacer intelligemment ! N'oubliez pas d'essayer différentes méthodes de remplacement et de mesurer leur impact sur les performances de votre modèle. Examinons maintenant notre jeu de données Titanic :"
      ]
    },
    {
      "metadata": {
        "_uuid": "c8da6fc848902000a7b356dfa59f11b5d0b988fa",
        "id": "1AafYY5B8muL"
      },
      "cell_type": "markdown",
      "source": [
        "### Il ne manque que deux valeurs pour la colonne « Embarqué ». Essayons de les remplacer. Voici la répartition des « Embarqués » selon le tarif et le sexe, ainsi que les deux observations pour lesquelles la valeur « Embarqué » est manquante. Analysons ces deux observations et choisissons la valeur « Embarqué » la plus adaptée en fonction de leur tarif et de leur sexe :"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e5d71f475f8236bd0df71852f6a52e4889026562",
        "id": "5R2ETm5_8muL"
      },
      "cell_type": "code",
      "source": [
        "figure, axes = plt.subplots(1,1,figsize=(20, 8))\n",
        "plot = sns.catplot(x=\"Embarked\", y=\"Fare\", hue=\"Sex\", data=titanic_df, palette=('nipy_spectral'), kind=\"bar\", ax=axes)\n",
        "plt.close(plot.fig)\n",
        "plt.show()\n",
        "display(titanic_df[titanic_df['Embarked'].isnull()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "96d8fa62c76b2e756e501444c99552dd4aa98829",
        "id": "jC_LLgOe8muM"
      },
      "cell_type": "markdown",
      "source": [
        "### Les deux passagères sont des femmes qui ont payé 80 dollars pour leur billet. De plus, elles ont le même billet et la même cabine ; elles ont donc probablement dû embarquer au même endroit ! D'après la distribution ci-dessus, la valeur d'embarquement la plus probable pour elles est Cherbourg (C). Remplaçons ces valeurs manquantes :"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "160380a05b7fe957b109da0290ee446ff933c85b",
        "id": "E9FXyEzg8muM"
      },
      "cell_type": "code",
      "source": [
        "titanic_df['Embarked'].fillna('C', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1680eb602baf52fec30bc425f0fca7d6a92e214d",
        "id": "hzSK8HKo8muM"
      },
      "cell_type": "markdown",
      "source": [
        "### Pour l'âge, nous avons 177 valeurs manquantes ; c'est beaucoup trop pour les examiner au cas par cas. Nous allons la remplacer par la médiane, même s'il existe peut-être une meilleure solution prenant en compte d'autres colonnes. Si vous trouvez une solution pour remplacer les valeurs d'âge manquantes qui améliore considérablement la précision de votre modèle, n'hésitez pas à la partager dans les commentaires !"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3713234249422bee05b53f333ab127f551ca7934",
        "id": "Ofh27naw8muM"
      },
      "cell_type": "code",
      "source": [
        "titanic_df['Age'].fillna(titanic_df['Age'].median(), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b9a4bcc1d712e8a283f201afa5ffd777e311452a",
        "id": "5mbIc2jq8muM"
      },
      "cell_type": "markdown",
      "source": [
        "### Enfin, la colonne « Cabin » (cabine) permet de trouver le pont où se trouve la cabine du passager : nous la conserverons donc. Remplaçons les valeurs manquantes par « U », c'est-à-dire 'Unkown':"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "892039639905363f4e5e26736e83bfe2cb2671e7",
        "id": "hpdNJiYP8muM"
      },
      "cell_type": "code",
      "source": [
        "titanic_df['Cabin'].fillna('U', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "658a2ae96bf806569521ea616ec3cba49a452cb3",
        "id": "XUap7DBM8muM"
      },
      "cell_type": "code",
      "source": [
        "draw_missing_data_table(titanic_df[['Cabin', 'Age', 'Embarked']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P-8xpMPmbzZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fcdf726a3377e5f093b178fcae07651662eb3e0e",
        "id": "uFRKyI0F8muM"
      },
      "cell_type": "markdown",
      "source": [
        "## **2. Ingénierie des caractéristiques** <a id=\"2\"></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "94def9bb6e7d8e66e0c47ded26ef10243883072c",
        "id": "UqLRgcVX8muM"
      },
      "cell_type": "markdown",
      "source": [
        "### L'ingénierie des caractéristiques est l'art de créer de nouvelles caractéristiques à partir de caractéristiques existantes ou de connaissances sur les données. Par exemple, une simple recherche sur Internet permet de déterminer que la première lettre de la colonne « cabine » correspond au pont du bateau où se trouve la cabine. Ainsi, nous pouvons créer une entité « Pont » à partir de la caractéristiques « cabine ». Nous pouvons également créer une colonne « Titre » correspondant au titre de chaque passager. La création de caractéristiques est la seule limite ! Mais gardez à l'esprit que l'objectif n'est pas de créer des caractéristiques simplement pour créer des caractéristiques, mais d'améliorer la précision du modèle ! Voici quelques exemples de création de caractéristiques pour le jeu de données Titanic :"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8daa8401d9316696a5bdecad95807c5e593649ec",
        "id": "t62lsXM68muM"
      },
      "cell_type": "code",
      "source": [
        "# Deck column from letter contained in cabin\n",
        "titanic_df['Deck'] = titanic_df['Cabin'].str[:1]\n",
        "titanic_df['Deck'] = titanic_df['Cabin'].map({cabin: p for p, cabin in enumerate(set(cab for cab in titanic_df['Cabin']))})\n",
        "\n",
        "# Title column from title contained in name\n",
        "titanic_df['Title'] = pd.Series((name.split('.')[0].split(',')[1].strip() for name in titanic_df['Name']), index=titanic_df.index)\n",
        "titanic_df['Title'] = titanic_df['Title'].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "titanic_df['Title'] = titanic_df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
        "titanic_df['Title'] = titanic_df['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "# Famillysize columns obtained by adding number of sibling and parch\n",
        "titanic_df['FamillySize'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1\n",
        "titanic_df['FamillySize'][titanic_df['FamillySize'].between(1, 5, inclusive='neither')] = 2\n",
        "titanic_df['FamillySize'][titanic_df['FamillySize']>5] = 3\n",
        "titanic_df['FamillySize'] = titanic_df['FamillySize'].map({1: 'Alone', 2: 'Medium', 3: 'Large'})\n",
        "\n",
        "# IsAlone and IsChild column, quite explicit\n",
        "titanic_df['IsAlone'] = np.where(titanic_df['FamillySize']!=1, 0, 1)\n",
        "titanic_df['IsChild'] = titanic_df['Age'] < 18\n",
        "titanic_df['IsChild'] = titanic_df['IsChild'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d118e47ade8afeba0d947d24ac45eca4d1277338",
        "id": "21V0nF5f8muN"
      },
      "cell_type": "markdown",
      "source": [
        "### Once we've finished to create our new features, we can delete all useless remaining columns and print the first rows of our dataset:"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f55056111610891accfda70fcc8fee07a84eefb",
        "id": "E76qypbY8muN"
      },
      "cell_type": "code",
      "source": [
        "titanic_df = titanic_df.drop(['Name', 'Ticket', 'PassengerId', 'Cabin'], axis=1)\n",
        "titanic_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c6a2b251a8ae431def02d1c23ff6c0aa2792c370",
        "id": "Q_ybhk-08muN"
      },
      "cell_type": "markdown",
      "source": [
        "## **3. Gestion des fonctionnalités catégorielles** <a id=\"3\"></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "c153f7f9e43c2b84925f110ca597a59d92a47f42",
        "id": "7U_aaIMq8muN"
      },
      "cell_type": "markdown",
      "source": [
        "### Comme vous pouvez le constater en examinant l'ensemble de données ci-dessus, nos données contiennent des caractéristiques catégorielles.\n",
        "### Ces caractéristiques sont des caractéristiques dont les valeurs ne sont pas numériques.\n",
        "### Nous avons quatre colonnes de type catégorie :\n",
        "  - Sex\n",
        "  - Embarked\n",
        "  - Title\n",
        "  - FamilySize\n",
        "\n",
        "### Nous devons les transformer en caractéristiques numériques afin de les transmettre à un algorithme de machine learning.\n",
        "### Une solution consiste à transformer ces caractéristiques en caractéristiques numériques en mappant les valeurs de chaîne avec des valeurs numériques. Cette solution est appelée \"label encoding\" (codage d'étiquettes).\n",
        "### Elle est facile à réaliser en Python à l'aide de la classe LabelEncoder de Scikit Learn ou de la méthode map d'un dataframe Pandas.\n",
        "### Par exemple, pour encoder par étiquette la colonne \"Embarked\" du jeu de données Titanic, nous allons créer de nouvelles colonnes à partir de \"embarked\" en y ajoutant la lettre de la ville d'embarquement  : la valeur \"string\" de la ville sera remplacé par une valeur de type \"number\" distincte dans les 3 colonnes crées correspondant au lieu d'embarquement :\n",
        "\n",
        "- Embarqué à Cherbourg (\"Embarked_C\") correspond à 1\n",
        "- Embarqué à Southampton (\"Embarked_S\") correspond à 2\n",
        "- Embarqué à Queenstown (\"Embarked_Q\") correspond à 3\n",
        "\n",
        "### Le problème est que l'algorithme peut interpréter cela comme un classement entre les trois valeurs.\n",
        "\n",
        "## Une meilleure solution consiste à utiliser l'encodage « hot-one ». Ce codage consiste à créer une colonne par valeur de la colonne source (appelée variable muette), qui prend uniquement des valeurs binaires. Par exemple, la colonne « embarked » « dummy encoded » donne trois colonnes : Embarked_C, Embarked_S et Embarked_Q. Par exemple, la colonne « Embarked_S » d'un passager ayant embarqué à Southampton sera définie à 1, tandis que les deux autres colonnes « embarked » seront définies à 0.\n",
        "\n",
        "![](https://www.renom.jp/notebooks/tutorial/preprocessing/category_encoding/renom_cat_onehot.png)\n",
        "\n",
        "### Cependant, cette méthode crée une colonne redondante : avec deux des trois colonnes « Embarked », on peut facilement deviner la valeur de la troisième colonne. Par exemple, un passager dont les colonnes Embarked_C et Embarked_S sont définies à 0 aura nécessairement sa colonne Embarked_Q définie à 1. Afin d'éviter cette redondance, appelée piège de la variable factice, nous devons supprimer l'une des colonnes créées lors de la création d'une variable factice.\n",
        "\n",
        "*Remarque : L'encodage one-hot est généralement efficace, mais cela peut varier au cas par cas. N'hésitez pas à tester l'effet de l'encodage one-hot sur votre modèle pour voir si vous en avez besoin.*\n",
        "\n",
        "### Il existe une méthode très simple pour effectuer un encodage one-hot en Python : la fonction pandas get_dummies crée un encodage one-hot pour toutes les caractéristiques catégorielles d'un jeu de données. En ajoutant l'argument drop_first=True, nous supprimons une colonne pour chaque variable factice à encoder."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2cd8757a652f90674dfb6972f99c3b55a225a397",
        "id": "R_YuVC-X8muN"
      },
      "cell_type": "code",
      "source": [
        "titanic_df = pd.get_dummies(data=titanic_df, drop_first=True)\n",
        "titanic_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ea021e657727b1e65c9cada661ed5ae492c62202",
        "id": "MJuUm4Jq8muN"
      },
      "cell_type": "markdown",
      "source": [
        "## **4. Mise à l'échelle des caractéristiques** <a id=\"4\"></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "ba96a06d76b3a858459486ceb0af2340a7799074",
        "id": "4b9sAO8M8muN"
      },
      "cell_type": "markdown",
      "source": [
        "### Finally, we need to perform normalization on the data. Normalizing the data is necessary because feeding a machine learning model with large or heterogeneous values can trigger large gradient updates that will prevent the gradient descent algorithm from converging. Let's look at the ranges of values for our dataframe:"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hw5lbp0a8muN"
      },
      "cell_type": "code",
      "source": [
        "ranges = titanic_df[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Deck', 'IsChild']].max().to_frame().T\n",
        "ranges.iplot(kind='bar', xTitle='Features', yTitle='Range', title='Range of feature before scaling')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pxWDqCRA8muN"
      },
      "cell_type": "markdown",
      "source": [
        "### Ranges are very heterogeneous. One way to change this is by using features scaling. Features scaling will set each column mean to 0 and each column variance to 1. In python, the StandarScaler class of the scikit-learn module allows us to do it vey easily:"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46fdee99c06403f18ef1201671c3c8903193e8c4",
        "id": "6VPiiOOq8muN"
      },
      "cell_type": "code",
      "source": [
        "X = titanic_df.drop(['Survived'], 1)\n",
        "y = titanic_df['Survived']\n",
        "\n",
        "# Feature scaling of our data\n",
        "sc = StandardScaler()\n",
        "X = pd.DataFrame(sc.fit_transform(X.values), index=X.index, columns=X.columns)\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "926c3da68404487f08462c699bb4725d819578b9",
        "id": "BSFFFNZO8muO"
      },
      "cell_type": "markdown",
      "source": [
        "### And ... we are done ! Our dataset is finally ready to go into a machine learning algorithm ! Don't forget to check my two others kernel for this dataset:\n",
        "\n",
        "- [**Complete Titanic tutorial with ML, NN & Ensembling**](https://www.kaggle.com/nhlr21/complete-titanic-tutorial-with-ml-nn-ensembling)\n",
        "- [**Titanic colorful EDA**](https://www.kaggle.com/nhlr21/titanic-colorful-eda)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}